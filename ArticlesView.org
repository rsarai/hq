# This file is AUTOGENERATED by /home/sarai/github-projects/hq/hq/views/articles.py
# It's deliberately read-only, because it will be overwritten next time Orger is run.
# If you want to edit it anyway, you can use chmod +w in your terminal, or M-x toggle-read-only in Emacs.

#+title: How I Did More By Doing Less. Because we all feel better when we can... | by Michel Kana, Ph.D | Feb, 2021 | Medium [2021-03-04 Thu 00:00]
- * How I Did More By Doing Less. Because we all feel better when we can... | by Michel Kana, Ph.D | Feb, 2021 | Medium
-   :PROPERTIES:
-   :CUSTOM_ID: how-i-did-more-by-doing-less.-because-we-all-feel-better-when-we-can-by-michel-kana-ph.d-feb-2021-medium
-   :END:

- Date :: Mar 4, 2021 9:57 AM
- URL :: https://michel-kana.medium.com/how-i-did-more-by-doing-less-705130fb43f1

#+caption: How%20I%20Did%20More%20By%20Doing%20Less%20Because%20we%20all%20feel%20b%20e203855f599a476bb59c92acebff248a/10E6Dn5OIhB6ZWEZuirrXfA.jpeg
- [[file:How%20I%20Did%20More%20By%20Doing%20Less%20Because%20we%20all%20feel%20b%20e203855f599a476bb59c92acebff248a/10E6Dn5OIhB6ZWEZuirrXfA.jpeg]]

- Photo by [[https://unsplash.com/@robbie36][Robert Collins]] on Unsplash

#+begin_quote
-   Have you ever got something by doing nothing?
#+end_quote

- Most of us believe that the harder we work the more we receive. What do we receive? More money, security, social status. What about happiness?

- In my life, I spent a lot of time achieving more by doing even more. One university degree was not enough, I got several of them and later a Ph.D. Speaking one language was not enough, I learned many additional ones. Working full-time was not enough, I founded my own startup.

- Doing more became a never-ending story. Several years ago I decided to take a new job and to do only that job. I was quite excited and persuaded that I will be doing less.

- That was an illusion. Inside the job I was over-performing, going the extra mile. Apart from my technical job responsibilities, I turned to become a personal coach, listener, mentor, life advisor, and leadership builder. This required me to control my emotions and to show vulnerability and build trust.

- This was too much. I was doing too much again. Things stopped working.

- I had the feeling to endanger other colleague's interests and career goals. I was cursed for being too good, too nice. It hurt when doing more and receiving less. Feelings of deception, anger, fear became my daily companion.

- Those feelings consumed me from within as I started making bad decisions, displaying inappropriate behaviors, becoming a shadow of myself. This crazy ride went on like a never-ending story.

- Luckily, soon enough, I realized that it was all about my thoughts. There was me on one side and my dark thoughts and negative emotions on the other side. I decided to become more aware of my thoughts and emotions while trying not to control them.

- I started embracing my need for social acceptance, recognizing my ego, identifying the triggers of my insecurity, being aware of my misconceptions about colleagues and other beliefs.

- I have become a student of my own life. Now I know what's happening and it is fine because it is me and it is life. I am thankful for experiencing these moments while learning about myself. I cherish contemplating who I truly am.

- When you observe the thoughts generated in your mind, you can follow them, from the shore like a river. The flow is dynamic and passionate. You discover the marvel of the mind, that is generating so much richness. You do not judge yourself anymore, you stop fighting others in your mind because you have just realized that your mind is the only one generating the thoughts.

- You can't believe how much fun it is to be able to change the focus of your mind at any time, as a conscious choice. You are in control.

- I realized that doing more does not define my happiness, but it is my thoughts, which ultimately create the illusion of being happy or unhappy.

- Thanks to practicing mindfulness and self-awareness, I got better at disconnecting from my thoughts. These are the moments when I see my colleagues as they are, the business problems and opportunities are crystal clear. My team performance increases. I am really delighted for doing less, but achieving more for people around me and people around those people.

#+begin_quote
-   Finding the right balance between doing less and doing more is a key to happiness.
#+end_quote

- Our default belief is that we have to care. However doing less can be a much more appropriate option. Doing less is not laziness. It is rather what tells the world who I am and what is my purpose. Why I am born.

- Doing less is not procrastination. It instead nurtures the positive beliefs which support my journey after setting an intention in my mind. That is a dream I have, a very specific higher achievement I am aiming for, not just for me.

- This is why, every day you can dare a bit more to nurture yourself on that specific individual journey.

- Doing less is a release of tension, the end of finger-pointing at others, the end of illusion about the self, and the beginning of freedom.

- The Covid-19 pandemic is teaching us how important it is to be kind to ourselves.

#+begin_quote
-   Do more by doing less.
#+end_quote

#+caption: How%20I%20Did%20More%20By%20Doing%20Less%20Because%20we%20all%20feel%20b%20e203855f599a476bb59c92acebff248a/1f-TZFiovLge0S72RcnDS_w.jpeg
- [[file:How%20I%20Did%20More%20By%20Doing%20Less%20Because%20we%20all%20feel%20b%20e203855f599a476bb59c92acebff248a/1f-TZFiovLge0S72RcnDS_w.jpeg]]

- Photo by [[https://pixabay.com/users/leroy_skalstad-1202818/][Leroy_Skalstad]] on Pixabay

#+title: Yoshua Bengio Team Proposes Causal Learning to Solve the ML Model Generalization Problem | Synced [2021-03-04 Thu 00:00]
- * Yoshua Bengio Team Proposes Causal Learning to Solve the ML Model Generalization Problem | Synced
-   :PROPERTIES:
-   :CUSTOM_ID: yoshua-bengio-team-proposes-causal-learning-to-solve-the-ml-model-generalization-problem-synced
-   :END:

- Date :: Mar 4, 2021 9:57 AM
- URL :: https://syncedreview.com/2021/03/01/yoshua-bengio-team-proposes-causal-learning-to-solve-the-ml-model-generalization-problem/

#+caption: Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-25.png
- [[file:Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-25.png]]

- Understanding and generalization beyond the training distribution are regarded as huge challenges in modern machine learning (ML) --- and Yoshua Bengio argues it's time to look at causal learning for possible solutions. In the paper /Towards Causal Representation Learning,/ Turing Award honoree Bengio and his research team make an effort to unite causality and ML research approaches, delineate some implications of causality for ML, and propose critical areas for future research.

#+caption: Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-6.png
- [[file:Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-6.png]]

- Bengio outlined the challenge in a causal representation learning [[https://www.youtube.com/watch?v=rKZJ0TJWvTk&ab_channel=BradyNeal-CausalInference][talk]] he gave late last year, "I would say there are pretty significant gaps between current state-of-the-art in machine learning-driven AI and the intelligence that we see deployed in humans and many animals... We don't have AI systems that actually understand at the level that humans do, or anywhere close." Bengio characterized the meaning of human-level AI "understanding" as: capture causality; capture how the world works; understand abstract actions and how to use them to control; reason and plan, even in novel scenarios; explain what happened (inference, credit assignment); and generate out-of-distribution.

- In this regard, most modern ML models remain far from true understanding, as they work only under fixed experimental conditions and interventions in the real world are seen as a nuisance that can hopefully be engineered away. It is therefore not surprising that most of today's ML models lack an out-of-distribution generalization ability.

- Causal learning, on the other hand, focuses on representing structural knowledge about the data-generating process to allow interventions and changes, making it easier to re-use and re-purpose learned knowledge. This approach is considered closer to human thinking.

- The new paper reviews and synthesizes a number of important contributions to causal learning, specifically:

- - Describing different levels of modelling in physical systems and presenting the differences between causal and statistical models.
- - Expanding on the Independent Causal Mechanisms (ICM) principle as a key component that enables the estimation of causal relations from data.
- - Reviewing existing approaches to learn causal relations from appropriate descriptors (or features).
- - Discussing how useful models of reality may be learned from data in the form of causal representations, and discussing several current ML problems from a causal point of view.
- - Assaying the implications of causality for practical machine learning, discussing examples at the intersection between causality and ML in scientific applications and speculating on the advantages of combining the strengths of both fields to build a more versatile AI.

#+caption: Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-7.png
- [[file:Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-7.png]]

- Level of modelling in physical systems

- The paper classifies models on three levels: mechanistic or physical models, casual models and statistical models. The most detailed are mechanistic or physical models, which are usually differential equations that provide comprehensive system descriptions. Unlike differential equations, which typically require input from human experts, causal modelling is in a more data-driven approach, replacing expert knowledge with weak and generic assumptions. The most superficial of the model types are statistical, which do not use dynamic processes and only make predictions based on some variables under fixed experimental conditions.

- A strong ML model depends on an independent and identically distributed random variables (i.i.d.) data assumption. In other words, the conceptual basis of statistical learning is a joint distribution. Causal learning, meanwhile, allows inference on data with interventions (no need to assume that data are i.i.d.) and can provide understanding and predict the effect of interventions. This differs from statistical models, which only allow inference on i.i.d. experiments.

#+caption: Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-8.png
- [[file:Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-8.png]]

- Difference between statistical (left) and causal models (right) on a given set of three variables.

- The researchers propose that insights on the differences between statistical and causal models can be expressed as the Independent Causal Mechanisms (ICM) Principle (proposed by B. Schölkopf in 2012), where the causal generative process of a system's variables is composed of autonomous modules that do not inform or influence each other. In the probabilistic case, this means that the conditional distribution of each variable given its causes (i.e., its mechanism) does not inform or influence the other mechanisms.

- The researchers expand the ICM principle and describe the sparse mechanism shift hypothesis as Sparse Mechanism Shift (SMS), where small distribution changes tend to manifest themselves in a sparse or local way in the causal/disentangled factorization, i.e., they should usually not affect all factors simultaneously.

- The researchers also look at causal representation learning's connection to the recent interest in the concept of disentangled representations in deep learning, and discuss how ML models can benefit from causal learning with regard to semi-supervised learning, domain generalization, and adversarial robustness.

- Finally, the team proposes a number of critical areas for future research: learning non-linear causal relations at scale; learning causal variables; understanding of bias in existing deep learning approaches; and learning causally correct models of the world and the agent.

- The authors are from Max-Planck Institute for Intelligent Systems, ETH Zurich, Google Research Amsterdam, Mila and the University of Montreal. The paper /Towards Causal Representation Learning/ is on [[https://arxiv.org/pdf/2102.11107.pdf][arXiv]].

- *Author*: Hecate He | *Editor*: Michael Sarazen

#+caption: Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-122.png
- [[file:Yoshua%20Bengio%20Team%20Proposes%20Causal%20Learning%20to%20Sol%209505fb540935497a8c88f2ad0b61caf4/image-122.png]]

- We know you don't want to miss any news or research breakthroughs. *Subscribe to our popular newsletter /[[https://mailchi.mp/2fb3aa308ad3/welcome-to-synced-global-ai-weekly-newsletter][Synced Global AI Weekly]]/ to get weekly AI updates.*
